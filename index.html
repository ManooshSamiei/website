<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Manoosh Samiei</title>
  
  <meta name="author" content="Manoosh Samiei">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Manoosh Samiei</name>
              </p>
              <p>I am a computer vision researcher at <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjz5Y2R4bj5AhUbkYkEHfw0Cn0QFnoECBMQAQ&url=https%3A%2F%2Falgolux.com%2F&usg=AOvVaw3FVHvRDBmZHK__oN5p6Mgh">Algolux</a>, where I work on computer vision and machine learning algorithms for autonomous vehicles perception. At Algolux, I have mainly worked on lane boundary, road curb, and freespace segmentation.
              </p>
              <p>
               I did my masters at <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwim1-_Z4bj5AhWkhIkEHRV3CcEQFnoECAkQAQ&url=https%3A%2F%2Fwww.mcgill.ca%2Fece%2Ffacultystaff&usg=AOvVaw2zhC4vvKsSDWKjoFEoe_-H">McGill</a> in Electrical and Computer Engineering, where I was advised by <a href="http://www.cim.mcgill.ca/~clark/">James J. Clark</a>. My master's research was on modeling visual attention and distraction in visual search tasks. At McGill and Algolux, I have worked on image segmentation, object detection and saliency prediction. 
                 </p>
              <p>            
I did my undergraduate at Shahid Beheshti University in Electrical Engineering with a focus on telecommunications and signal processing. My undergraduate research was focused on end-to-end training approach for lane
following task (behavioral clonning) in autonomous vehicles using convolutional neural networks. During my undergraduate, I worked on multiple robotic projects and learned about electronic circuits troubleshooting and assembly.                 </p>
              <p>  My research interests lie at the intersection of human vision, robotics, computer vision and machine learning. Besides AI and programming, I also enjoy hardware assembly and electronic circuitry.
              </p>
              <p style="text-align:center">
                <a href="mailto:manoosh.samiei@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/manoosh-samiei-2386a1190/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=PEVAoSkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/SamieiManoosh">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/ManooshSamiei">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Manoosh_.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/manoosh.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Highlights</heading>
              <p>
                <strong>09/08/2022</strong> Moving to Toronto, Ontario on 1st September!
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" id='visual_search'>
                  <img src='images/visual-search.jpg' width="160"></div>
              <script type="text/javascript">
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              	Master Research, 2021<br>
                <papertitle>Predicting Visual Attention and Distraction During Visual Search Using Convolutional Neural Networks</papertitle>
              <br>
              Manoosh Samiei, James J. Clark
              <br>
              Two Publications one in <em>Journal of Vision</em> and another in <em>Arxiv</em> are in progress.
              <br>
              <a href="https://github.com/ManooshSamiei/Distraction-Visual-Search">GitHub Code</a>
              /
              <a href="https://escholarship.mcgill.ca/concern/theses/5t34sq19q">Thesis</a>
              <p></p>
              <p>
We present two approaches. Our first method uses a two-stream encoder-decoder network to predict fixation density maps of human observers in visual search. Our second method predicts the segmentation of distractor and target objects during search using a Mask-RCNN segmentation network. We use COCO-Search18 dataset to train/finetune and evaluate our models.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" id='deepgaze'>
                <img src='images/deepgaze.jpg' width="160">
              </div>
              <script type="text/javascript">
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
                <papertitle>Implementing DeepGaze2 Free-viewing Saliency Model, 2020</papertitle>
              <br>
              <a href="http://jonbarron.info/mipnerf360">GitHub</a>
              /
              <a href="https://arxiv.org/abs/2111.12077">Report</a>
              <p></p>
              <p>DeepGaze2 extracts high-level features in images using VGG19 convolutional neural network pretrained for object recognition task. DeepGaze II is trained using a log-likelihood learning framework, and aims to predict where humans look while free-viewing a set of images.</p>
            </td>
          </tr> 
          				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" id='OD_RL'>

                <img src='images/OD_RL_1.png' width="160">
              </div>
              <script type="text/javascript">

              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
                <papertitle>Object Detection with Deep Reinforcement Learning, 2020</papertitle>
              <br>
							<a href="https://github.com/ManooshSamiei/Object-Detection-Deep-Reinforcement-Learning">GitHub</a> / 
							<a href="https://github.com/ManooshSamiei/Object-Detection-Deep-Reinforcement-Learning/blob/main/RL_object_detection.pdf">Report</a> / 
							<a href="https://youtu.be/dcGP9mDnFf0">video</a>			
              <p></p>
              <p>We implmented two papers that formulate object localization as a dynamic Markov decision process based on deep reinforcement learning. We compare two different action settings for this MDP: a hierarchical method and a dynamic method. </p>
            </td>
          </tr>

			    <tr>
			      <td style="padding:20px;width:25%;vertical-align:middle">
			        <div class="one" id='3d_object'>
			          <img src='images/3D.png' width="160">
			        </div>
			        <script type="text/javascript">
			        </script>
			      </td>
			            <td style="padding:20px;width:75%;vertical-align:top">
			            <papertitle>Reproducing CNN2: Viewpoint Generalization via a Binocular Vision, 2019</papertitle>
			          <br>
			          <a href="https://openreview.net/forum?id=jUJo2RYTOb">Report</a>
			          <p></p>
			          <p> We replicated the results of the paper ‚ÄúCNN2: Viewpoint Generalization via a Binocular Vision‚Äù for two datasets SmallNORB and ModelNet2D.</p>
			        </td>
			      </tr>
		
			    <tr>
			      <td style="padding:20px;width:25%;vertical-align:middle">
			        <div class="one" id='slf'>
			          <img src='images/slf.jpg' width="160">
			        </div>
			        <script type="text/javascript">
			        </script>
			      </td>
			            <td style="padding:20px;width:75%;vertical-align:top">
			            <papertitle>Implementation of End-to-End Behavioral Cloning Approach for Lane Following Task in Autonomous Vehicles using Convolutional Neural Networks. , 2019</papertitle>
			          <br>
			          <a href="https://drive.google.com/file/d/11b24VbK3d9jYsrMFm8ikz8AWEWoQKFgA/view?usp=sharing">Thesis in Persian</a>
			          <p> </p>
			        </td>
			      </tr>				
				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/poster.png" width="140"></td>
            <td width="75%" valign="top">
              <br>
              Volunteer in poster sessions in <a href="http://montrealaisymposium.com/"> Montreal AI Symposium 2020</a>
              , and 
              <a href="http://wimlds.org/">WiMLDS 2020</a>
              <br>
              Helped with locating posters and technical issues in gather town platform.
            </td>
          </tr>


					
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Source code and style from <a href="https://github.com/jonbarron/jonbarron_website"> Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
